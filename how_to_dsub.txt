#################################################################################

# How to run a custom R script with dsub
# David L Gibbs
# dgibbs@systemsbiology.org
# November 7, 2017

# https://cloud.google.com/genomics/overview

#################################################################################

# In this example, I'm going to be fitting Bayesian models for logistic Regression
# using Stan. (http://mc-stan.org/) Each job will process a single file,
# but we could also have each job represent a parameter set, or model, all
# processing the same data.

# 1. I searched for 'docker and RStan' and found some docker images.
# https://github.com/jburos/rstan-docker
# https://hub.docker.com/r/jackinovik/rstan-complete/

# 2. The data needs to be available in a google bucket.

# 3. Then we can call dsub using a task list, containing all the variables we
# need, including input and output paths. You can find that in 'cmd_generator.R',
# which writes out a table with the variables needed in each row.
# see this example: https://github.com/googlegenomics/dsub/tree/master/examples/custom_scripts

dsub \
  --project isb-cgc-02-0001 \
  --zones "us-west-*" \
  --logging gs://gibbs_bucket_nov162016/logs/ \
  --image jackinovik/rstan-complete \
  --script ./stan_logistic_regression.R \
  --tasks task_matrix.txt \
  --wait

# OK, it returns saying:
Running [operations/ENGopaL5KxiThuH18PenvxAg6YmPu4QUKg9wcm9kdWN0aW9uUXVldWU].

# 5. We can check it's status with:
gcloud alpha genomics operations describe operations/ENGopaL5KxiThuH18PenvxAg6YmPu4QUKg9wcm9kdWN0aW9uUXVldWU

# and if we/I forget the job ID, we can check using:
gcloud alpha genomics operations list | less

# Now, we can check our bucket for the output. If there's a problem, read the logs!
# DONE!
